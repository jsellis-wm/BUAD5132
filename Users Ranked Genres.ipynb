{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c50a9d",
   "metadata": {},
   "source": [
    "# Top 5 Genres by User\n",
    "\n",
    "### Environment\n",
    "\n",
    "The directory structure for this notebook is as follows:\n",
    "\n",
    "- root\n",
    "    - group\n",
    "        - Top 5 Genres by User.ipynb\n",
    "        - users_genres.csv (will output at the end of the notebook)\n",
    "    - ml-100k\n",
    "        - u.item\n",
    "        - u.data\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this Jupyter notebook, we use `pyspark` to determine the top 5 genres for each user based on the average rating for movies in each genre. To determine the top 5, we only include genres for which users have more than 10 movie ratings\n",
    "\n",
    "To begin our ranking, we import a few necessary pacakges from `pyspark`. Please ensure you have `pyspark` loaded in the virtual environment used to run this notebook. If your receive an error message telling you there is no module named `pyspark`, please see this [Stack Overflow](https://stackoverflow.com/questions/34302314/no-module-name-pyspark-error/34347373) post to help troubleshoot. Just make sure that if you are using anaconda, you install `pyspark` with `conda install pyspark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e7386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pyspark dependencies\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828ca79",
   "metadata": {},
   "source": [
    "### The Setup\n",
    "\n",
    "Before we can do anything with Spark, we must instantiate our session. Additionally, we will grab the Spark context from the session to help with importing the user data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "159c2dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Spark session\n",
    "spark = SparkSession.builder.config(\"spark.sql.warehouse.dir\", \"file:///C:/temp\").appName(\"UsersRankedGenres\").getOrCreate()\n",
    "\n",
    "# get the Spark context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b640f2a",
   "metadata": {},
   "source": [
    "Next, we define a mapping function to import the data into the Spark context. Then, we read the `u.item` file and convert it to a DataFrame. Finally, we create a table for use with SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364fc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to read in items\n",
    "def item_mapper(line):\n",
    "    fields = line.split(\"|\")\n",
    "    return Row( \\\n",
    "        MovieId = int(fields[0]), \\\n",
    "        MovieTitle = fields[1], \\\n",
    "        ReleaseDate = fields[2], \\\n",
    "        VideoReleaseDate = fields[3], \\\n",
    "        IMDBURL = fields[4], \\\n",
    "        Unknown = fields[5], \\\n",
    "        Action = fields[6], \\\n",
    "        Adventure = fields[7], \\\n",
    "        Animation = fields[8], \\\n",
    "        Childrens = fields[9], \\\n",
    "        Comedy = fields[10], \\\n",
    "        Crime = fields[11], \\\n",
    "        Documentary = fields[12], \\\n",
    "        Drama = fields[13], \\\n",
    "        Fantasy = fields[14], \\\n",
    "        FilmNoir = fields[15], \\\n",
    "        Horror = fields[16], \\\n",
    "        Musical = fields[17], \\\n",
    "        Mystery = fields[18], \\\n",
    "        Romance = fields[19], \\\n",
    "        SciFi = fields[20], \\\n",
    "        Thriller = fields[21], \\\n",
    "        War = fields[22], \\\n",
    "        Western = fields[23])\n",
    "    \n",
    "# get the items text file\n",
    "items_rdd = sc.textFile(\"../ml-100k/u.item\").map(item_mapper)\n",
    "\n",
    "# create items DataFrame and store it as a table\n",
    "items = spark.createDataFrame(items_rdd).cache()\n",
    "items.createOrReplaceTempView(\"items\")\n",
    "\n",
    "items.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f3a9dc",
   "metadata": {},
   "source": [
    "We currently have a \"wide\" DataFrame with each genre represented by its own column. In order for us to create a list of each users top 5 genres in the application, we want the DataFrame to the \"long\" with a single column that holds the genres. That being the case, we \"unpivot\" the individual genre columns using a `stack` expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a8eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a stack expression to unpivot the items DataFrame\n",
    "unpivot = \"stack(19, 'Unknown', Unknown, 'Action', Action, 'Adventure', Adventure, 'Animation', Animation, \\\n",
    "              'Childrens', Childrens, 'Comedy', Comedy, 'Crime', Crime, 'Documentary', Documentary, \\\n",
    "              'Drama', Drama, 'Fantasy', Fantasy, 'FilmNoir', FilmNoir, 'Horror', Horror, 'Musical', \\\n",
    "              Musical, 'Mystery', Mystery, 'Romance', Romance, 'SciFi', SciFi, 'Thriller', Thriller, \\\n",
    "              'War', War, 'Western', Western) AS (Genre, Value)\"\n",
    "\n",
    "# unpivot the items DataFrame so that the genres are in a single column and store it as a table\n",
    "item_genres = items.select(\"MovieId\", expr(unpivot)).where(\"Value > 0\").select(\"MovieId\", \"Genre\")\n",
    "item_genres.createOrReplaceTempView(\"item_genres\")\n",
    "\n",
    "item_genres.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eba5bf",
   "metadata": {},
   "source": [
    "Now that we have the items and associated genres in a \"long\" DataFrame, we can join that to the movie ratings to determine each users average rating for each genre. To do that, we first need to read in the ratings file.\n",
    "\n",
    "We begin by defining a mapping function to import the data into the Spark context. Then, we read the `u.data` file and convert it to a DataFrame. Finally, we create a table for use with SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc8890c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|UserId|ItemId|Rating|\n",
      "+------+------+------+\n",
      "|   196|   242|     3|\n",
      "|   186|   302|     3|\n",
      "|    22|   377|     1|\n",
      "|   244|    51|     2|\n",
      "|   166|   346|     1|\n",
      "+------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define a function to read in rating\n",
    "def rating_mapper(line):\n",
    "    fields = line.split(\"\\t\")\n",
    "    return Row( \\\n",
    "        UserId = int(fields[0]), \\\n",
    "        ItemId = int(fields[1]), \\\n",
    "        Rating = int(fields[2]))\n",
    "    \n",
    "# get the rating text file\n",
    "ratings_rdd = sc.textFile(\"../ml-100k/u.data\").map(rating_mapper)\n",
    "\n",
    "# create ratings DataFrame and store it as a table\n",
    "ratings = spark.createDataFrame(ratings_rdd).cache()\n",
    "ratings.createOrReplaceTempView(\"ratings\")\n",
    "\n",
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff0d76",
   "metadata": {},
   "source": [
    "We use Spark SQL now to join the `item_genres` table to the ratings table. Using that joined table, we determine the total number of ratings and the average of all ratings for each movie, but only return those that have more than 10 ratings.\n",
    "\n",
    "After storing the aggregating ratings query results as a DataFrame, we use another SQL query to rank each genre by user, then return the top 5 genres for each user. Finally, we save the top 5 genres DataFrame as a CSV for consumption in the recommender application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84fce18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----+------------+-------------+\n",
      "|UserId|   Genre|Rank|TotalRatings|AverageRating|\n",
      "+------+--------+----+------------+-------------+\n",
      "|     1|   SciFi|   1|          43|          4.0|\n",
      "|     1| Romance|   2|          44|        3.932|\n",
      "|     1|   Drama|   3|         107|        3.925|\n",
      "|     1|     War|   4|          25|         3.68|\n",
      "|     1|Thriller|   5|          52|        3.615|\n",
      "|     2| Romance|   1|          16|        4.125|\n",
      "|     2|   Drama|   2|          35|        3.829|\n",
      "|     2|  Comedy|   3|          16|        3.813|\n",
      "|     2|  Action|   4|          10|          3.8|\n",
      "|     2|Thriller|   5|          12|        3.583|\n",
      "+------+--------+----+------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join the genres to the ratings\n",
    "joined = ratings.join(item_genres, ratings.ItemId == item_genres.MovieId)\n",
    "joined.createOrReplaceTempView(\"joined\")\n",
    "\n",
    "# aggregate ratings by user and genre\n",
    "agg = spark.sql( \\\n",
    "    \"SELECT UserId, Genre, COUNT(*) AS TotalRatings, ROUND(AVG(Rating), 3) AS AverageRating \" \\\n",
    "    \"FROM joined \" \\\n",
    "    \"GROUP BY UserId, Genre \" \\\n",
    "    \"HAVING COUNT(*) >= 10 \" \\\n",
    "    \"ORDER BY UserId, AverageRating DESC\")\n",
    "\n",
    "# store the agg DataFrame as a table\n",
    "agg.createOrReplaceTempView(\"agg\")\n",
    "\n",
    "# get the top 5 genres for each user\n",
    "user_genres = spark.sql( \\\n",
    "        \"SELECT UserId, Genre, ROW_NUMBER() OVER (PARTITION BY UserId ORDER BY AverageRating DESC) AS Rank, TotalRatings, AverageRating \" \\\n",
    "        \"FROM agg \" \\\n",
    "        \"ORDER BY UserId, AverageRating DESC\").where(\"Rank <= 5\")\n",
    "\n",
    "user_genres.show(10)\n",
    "\n",
    "# save the top 5 genre DataFrame as a CSV for use in the recommender application\n",
    "user_genres.toPandas().to_csv(\"user_genres.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
